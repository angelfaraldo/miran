{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import madmom as mmm\n",
    "from miran import *\n",
    "from subprocess import call\n",
    "from time import time\n",
    "from sklearn import neighbors, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS PATHS\n",
    "sa_path = '/Users/angel/Git/miran/scripts/sonic-annotator'\n",
    "ff = folderfiles('/Users/angel/Desktop/')\n",
    "\n",
    "idx = 0\n",
    "beat_tracker = mmm.features.beats.DBNDownBeatTrackingProcessor(beats_per_bar=16, fps=100, downbeats=True)\n",
    "\n",
    "for f in ff:\n",
    "    if any(soundfile_type in f for soundfile_type in AUDIO_FILE_EXTENSIONS):\n",
    "        \n",
    "        i = time()\n",
    "        print(\"Analysing {}\".format(f), end='')\n",
    "        \n",
    "        # TEMPORARILY RENAME FILE TO AVOID ILLEGAL CHARACTERS.\n",
    "        fname, fext = os.path.splitext(f)\n",
    "        fdir, fname = os.path.split(fname)\n",
    "        fname = os.path.join(fdir, str(idx))\n",
    "        f2 = fname + fext\n",
    "        os.rename(f, f2)\n",
    "\n",
    "        # INIT PLACEHOLDERS\n",
    "        file_df = pd.DataFrame()\n",
    "        key     = [np.nan]\n",
    "        idist   = [np.nan]\n",
    "\n",
    "        # DOWNBEAT COMPUTATION\n",
    "        beat_activations = mmm.features.beats.RNNDownBeatProcessor()(f2)\n",
    "        downbeat_positions = beat_tracker(beat_activations)\n",
    "        \n",
    "        # VAMP-PLUGIN ANALYSIS\n",
    "        call('{0}/sonic-annotator -r -t {0}/nnls.n3 -w csv --csv-force \"{1}\"'.format(sa_path, f2), shell=True)\n",
    "        nnls = pd.read_csv(os.path.splitext(f2)[0] + '_vamp_nnls-chroma_nnls-chroma_chroma.csv', header=None)\n",
    "        \n",
    "        # ADD ZERO POSTION\n",
    "        if 0 not in downbeat_positions:\n",
    "            downbeat_positions = np.append(downbeat_positions, 0.00)\n",
    "            downbeat_positions = np.roll(downbeat_positions, 1)\n",
    "\n",
    "#         # MAKE CALCULATION BASED ON HYPERMETRICAL DIVISIONS\n",
    "#         for position in range(len(downbeat_positions) - 1):\n",
    "#             temp = nnls[nnls[0] >= downbeat_positions[position]]\n",
    "#             temp = nnls[nnls[0] <  downbeat_positions[position + 1]]\n",
    "#             mean_chroma = np.roll(temp.drop(0,1).median(), -3)\n",
    "#             key.append(clf.predict([mean_chroma])[0])\n",
    "#             dist = float(clf.kneighbors([mean_chroma],1)[0])\n",
    "#             idist.append(1 / dist)\n",
    "            \n",
    "#         # SAVE ALL RESULTS PER HYPERMEASURE TO PD DATAFRAME.\n",
    "#         file_df['downbeats'] = downbeat_positions\n",
    "#         file_df['key']       = np.roll(key, -1)\n",
    "#         file_df['idist']     = np.roll(idist, -1)\n",
    "        \n",
    "#         print(\" in {} seconds.\".format(time() - i))\n",
    "        \n",
    "#         # REMOVE INTERMEDIATE FILES AND RENAME WITH ORIGINAL NAME\n",
    "#         os.remove(os.path.splitext(f2)[0] + '_vamp_nnls-chroma_nnls-chroma_chroma.csv')\n",
    "#         os.rename(f2, f)\n",
    "#         idx += 1\n",
    "\n",
    "#         # MAKE GLOBAL KEY ESTIMATION BASED ON HYPERMETRICAL KEYS\n",
    "#         global_keys_candidates = []\n",
    "#         global_keys_confidence = []\n",
    "        \n",
    "#         # we add the distances of the closests candidates providing the same key\n",
    "#         for item in file_df.key.unique():\n",
    "#             if item != 'nan':\n",
    "#                 key_df = file_df[file_df.key == item]\n",
    "#                 global_keys_candidates.append(item)\n",
    "#                 global_keys_confidence.append(key_df.idist.sum())\n",
    "                \n",
    "#         global_key = global_keys_candidates[global_keys_confidence.index(max(global_keys_confidence))]\n",
    "        \n",
    "#         # SAVE SINGLE GLOBAL ESTIMATION TO TEXT FILE AND REMOVE INTERMEDIATE FILES\n",
    "#         global_key_dir = '/Users/angel/Desktop/test_keys'\n",
    "#         with open(os.path.join(global_key_dir, os.path.split(os.path.splitext(f)[0])[1] + '.txt'), 'w') as textfile:\n",
    "#                   textfile.write(global_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
